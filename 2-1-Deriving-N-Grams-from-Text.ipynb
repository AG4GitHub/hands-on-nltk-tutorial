{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deriving N-Grams from Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [N-Gram-Based Text Categorization: Categorizing Text With Python by Alejandro Nolla](http://blog.alejandronolla.com/2013/05/20/n-gram-based-text-categorization-categorizing-text-with-python/)\n",
    "\n",
    "What are n-grams? See [here](http://cloudmark.github.io/Language-Detection/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Le temps est un grand maître, dit-on, le malheur est qu'il tue ses élèves.\"\n",
    "s = s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le',\n",
       " 'temps',\n",
       " 'est',\n",
       " 'un',\n",
       " 'grand',\n",
       " 'maître',\n",
       " 'dit',\n",
       " 'on',\n",
       " 'le',\n",
       " 'malheur',\n",
       " 'est',\n",
       " \"qu'il\",\n",
       " 'tue',\n",
       " 'ses',\n",
       " 'élèves']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(\"[a-zA-Z'`éèî]+\")\n",
    "s_tokenized = tokenizer.tokenize(s)\n",
    "s_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', ' ', ' ', 'l'),\n",
       " (' ', ' ', 'l', 'e'),\n",
       " (' ', 'l', 'e', ' '),\n",
       " ('l', 'e', ' ', 't'),\n",
       " ('e', ' ', 't', 'e'),\n",
       " (' ', 't', 'e', 'm'),\n",
       " ('t', 'e', 'm', 'p'),\n",
       " ('e', 'm', 'p', 's'),\n",
       " ('m', 'p', 's', ' '),\n",
       " ('p', 's', ' ', 'e'),\n",
       " ('s', ' ', 'e', 's'),\n",
       " (' ', 'e', 's', 't'),\n",
       " ('e', 's', 't', ' '),\n",
       " ('s', 't', ' ', 'u'),\n",
       " ('t', ' ', 'u', 'n'),\n",
       " (' ', 'u', 'n', ' '),\n",
       " ('u', 'n', ' ', 'g'),\n",
       " ('n', ' ', 'g', 'r'),\n",
       " (' ', 'g', 'r', 'a'),\n",
       " ('g', 'r', 'a', 'n'),\n",
       " ('r', 'a', 'n', 'd'),\n",
       " ('a', 'n', 'd', ' '),\n",
       " ('n', 'd', ' ', 'm'),\n",
       " ('d', ' ', 'm', 'a'),\n",
       " (' ', 'm', 'a', 'î'),\n",
       " ('m', 'a', 'î', 't'),\n",
       " ('a', 'î', 't', 'r'),\n",
       " ('î', 't', 'r', 'e'),\n",
       " ('t', 'r', 'e', ','),\n",
       " ('r', 'e', ',', ' '),\n",
       " ('e', ',', ' ', 'd'),\n",
       " (',', ' ', 'd', 'i'),\n",
       " (' ', 'd', 'i', 't'),\n",
       " ('d', 'i', 't', '-'),\n",
       " ('i', 't', '-', 'o'),\n",
       " ('t', '-', 'o', 'n'),\n",
       " ('-', 'o', 'n', ','),\n",
       " ('o', 'n', ',', ' '),\n",
       " ('n', ',', ' ', 'l'),\n",
       " (',', ' ', 'l', 'e'),\n",
       " (' ', 'l', 'e', ' '),\n",
       " ('l', 'e', ' ', 'm'),\n",
       " ('e', ' ', 'm', 'a'),\n",
       " (' ', 'm', 'a', 'l'),\n",
       " ('m', 'a', 'l', 'h'),\n",
       " ('a', 'l', 'h', 'e'),\n",
       " ('l', 'h', 'e', 'u'),\n",
       " ('h', 'e', 'u', 'r'),\n",
       " ('e', 'u', 'r', ' '),\n",
       " ('u', 'r', ' ', 'e'),\n",
       " ('r', ' ', 'e', 's'),\n",
       " (' ', 'e', 's', 't'),\n",
       " ('e', 's', 't', ' '),\n",
       " ('s', 't', ' ', 'q'),\n",
       " ('t', ' ', 'q', 'u'),\n",
       " (' ', 'q', 'u', \"'\"),\n",
       " ('q', 'u', \"'\", 'i'),\n",
       " ('u', \"'\", 'i', 'l'),\n",
       " (\"'\", 'i', 'l', ' '),\n",
       " ('i', 'l', ' ', 't'),\n",
       " ('l', ' ', 't', 'u'),\n",
       " (' ', 't', 'u', 'e'),\n",
       " ('t', 'u', 'e', ' '),\n",
       " ('u', 'e', ' ', 's'),\n",
       " ('e', ' ', 's', 'e'),\n",
       " (' ', 's', 'e', 's'),\n",
       " ('s', 'e', 's', ' '),\n",
       " ('e', 's', ' ', 'é'),\n",
       " ('s', ' ', 'é', 'l'),\n",
       " (' ', 'é', 'l', 'è'),\n",
       " ('é', 'l', 'è', 'v'),\n",
       " ('l', 'è', 'v', 'e'),\n",
       " ('è', 'v', 'e', 's'),\n",
       " ('v', 'e', 's', '.'),\n",
       " ('e', 's', '.', ' '),\n",
       " ('s', '.', ' ', ' '),\n",
       " ('.', ' ', ' ', ' ')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "generated_ngrams = ngrams(s, 4, pad_left=True, pad_right=True, left_pad_symbol=' ', right_pad_symbol=' ') # n = 4. Note we use s not s_tokenized here. s_tokenized would give something like word-level n-grams.\n",
    "generated_ngrams_list = list(generated_ngrams) # generated_ngrams by itself is a 'generator object'\n",
    "generated_ngrams_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Obtaining n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['   l',\n",
       " '  le',\n",
       " ' le ',\n",
       " 'le t',\n",
       " 'e te',\n",
       " ' tem',\n",
       " 'temp',\n",
       " 'emps',\n",
       " 'mps ',\n",
       " 'ps e',\n",
       " 's es',\n",
       " ' est',\n",
       " 'est ',\n",
       " 'st u',\n",
       " 't un',\n",
       " ' un ',\n",
       " 'un g',\n",
       " 'n gr',\n",
       " ' gra',\n",
       " 'gran',\n",
       " 'rand',\n",
       " 'and ',\n",
       " 'nd m',\n",
       " 'd ma',\n",
       " ' maî',\n",
       " 'maît',\n",
       " 'aîtr',\n",
       " 'ître',\n",
       " 'tre,',\n",
       " 're, ',\n",
       " 'e, d',\n",
       " ', di',\n",
       " ' dit',\n",
       " 'dit-',\n",
       " 'it-o',\n",
       " 't-on',\n",
       " '-on,',\n",
       " 'on, ',\n",
       " 'n, l',\n",
       " ', le',\n",
       " ' le ',\n",
       " 'le m',\n",
       " 'e ma',\n",
       " ' mal',\n",
       " 'malh',\n",
       " 'alhe',\n",
       " 'lheu',\n",
       " 'heur',\n",
       " 'eur ',\n",
       " 'ur e',\n",
       " 'r es',\n",
       " ' est',\n",
       " 'est ',\n",
       " 'st q',\n",
       " 't qu',\n",
       " \" qu'\",\n",
       " \"qu'i\",\n",
       " \"u'il\",\n",
       " \"'il \",\n",
       " 'il t',\n",
       " 'l tu',\n",
       " ' tue',\n",
       " 'tue ',\n",
       " 'ue s',\n",
       " 'e se',\n",
       " ' ses',\n",
       " 'ses ',\n",
       " 'es é',\n",
       " 's él',\n",
       " ' élè',\n",
       " 'élèv',\n",
       " 'lève',\n",
       " 'èves',\n",
       " 'ves.',\n",
       " 'es. ',\n",
       " 's.  ',\n",
       " '.   ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ngrams_list_joined = generated_ngrams_list\n",
    "\n",
    "for idx, val in enumerate(generated_ngrams_list):\n",
    "    generated_ngrams_list_joined[idx] = ''.join(val) # ''.join() is the way to call the str.join() method.\n",
    "generated_ngrams_list_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sorting n-grams by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_statistics = {}\n",
    "\n",
    "for ngram in generated_ngrams_list_joined:\n",
    "    if ngram not in ngrams_statistics:\n",
    "        ngrams_statistics.update({ngram: 1})\n",
    "    else:\n",
    "        ngram_occurrences = ngrams_statistics[ngram]\n",
    "        ngrams_statistics.update({ngram: ngram_occurrences + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' le ', 2),\n",
       " (' est', 2),\n",
       " ('est ', 2),\n",
       " ('   l', 1),\n",
       " ('  le', 1),\n",
       " ('le t', 1),\n",
       " ('e te', 1),\n",
       " (' tem', 1),\n",
       " ('temp', 1),\n",
       " ('emps', 1),\n",
       " ('mps ', 1),\n",
       " ('ps e', 1),\n",
       " ('s es', 1),\n",
       " ('st u', 1),\n",
       " ('t un', 1),\n",
       " (' un ', 1),\n",
       " ('un g', 1),\n",
       " ('n gr', 1),\n",
       " (' gra', 1),\n",
       " ('gran', 1),\n",
       " ('rand', 1),\n",
       " ('and ', 1),\n",
       " ('nd m', 1),\n",
       " ('d ma', 1),\n",
       " (' maî', 1),\n",
       " ('maît', 1),\n",
       " ('aîtr', 1),\n",
       " ('ître', 1),\n",
       " ('tre,', 1),\n",
       " ('re, ', 1),\n",
       " ('e, d', 1),\n",
       " (', di', 1),\n",
       " (' dit', 1),\n",
       " ('dit-', 1),\n",
       " ('it-o', 1),\n",
       " ('t-on', 1),\n",
       " ('-on,', 1),\n",
       " ('on, ', 1),\n",
       " ('n, l', 1),\n",
       " (', le', 1),\n",
       " ('le m', 1),\n",
       " ('e ma', 1),\n",
       " (' mal', 1),\n",
       " ('malh', 1),\n",
       " ('alhe', 1),\n",
       " ('lheu', 1),\n",
       " ('heur', 1),\n",
       " ('eur ', 1),\n",
       " ('ur e', 1),\n",
       " ('r es', 1),\n",
       " ('st q', 1),\n",
       " ('t qu', 1),\n",
       " (\" qu'\", 1),\n",
       " (\"qu'i\", 1),\n",
       " (\"u'il\", 1),\n",
       " (\"'il \", 1),\n",
       " ('il t', 1),\n",
       " ('l tu', 1),\n",
       " (' tue', 1),\n",
       " ('tue ', 1),\n",
       " ('ue s', 1),\n",
       " ('e se', 1),\n",
       " (' ses', 1),\n",
       " ('ses ', 1),\n",
       " ('es é', 1),\n",
       " ('s él', 1),\n",
       " (' élè', 1),\n",
       " ('élèv', 1),\n",
       " ('lève', 1),\n",
       " ('èves', 1),\n",
       " ('ves.', 1),\n",
       " ('es. ', 1),\n",
       " ('s.  ', 1),\n",
       " ('.   ', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter # The operator module exports a set of efficient functions corresponding to the intrinsic operators of Python. For example, operator.add(x, y) is equivalent to the expression x + y.\n",
    "\n",
    "ngrams_statistics_sorted = sorted(ngrams_statistics.items(), key=itemgetter(1), reverse=True)[0:300] # We only keep the 300 most popular n-grams. This was suggested in the original n-gram paper. reverse=True has it in descending order.\n",
    "ngrams_statistics_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
